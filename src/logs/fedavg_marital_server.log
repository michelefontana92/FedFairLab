message: {'global_checkpoint': 1,
          'global_early_stopping': 0,
          'train_global_score': 23.29455640912056,
          'val_accuracy': tensor(0.6324),
          'val_demographic_parity_Marital': tensor(0.),
          'val_f1': tensor(0.4933),
          'val_global_score': 25.17658152182897,
          'val_loss': tensor(37.1174, device='cuda:0'),
          'val_precision': tensor(0.4071),
          'val_recall': tensor(0.6324)}
message: {'global_checkpoint': 1,
          'global_early_stopping': 0,
          'train_global_score': 10.603393842776612,
          'val_accuracy': tensor(0.6798),
          'val_demographic_parity_Marital': tensor(0.1032),
          'val_f1': tensor(0.6254),
          'val_global_score': 11.835616707801819,
          'val_loss': tensor(5.2024, device='cuda:0'),
          'val_precision': tensor(0.6968),
          'val_recall': tensor(0.6798)}
message: {'global_checkpoint': 0,
          'global_early_stopping': 1,
          'train_global_score': 11.319136917591095,
          'val_accuracy': tensor(0.6770),
          'val_demographic_parity_Marital': tensor(0.0964),
          'val_f1': tensor(0.6172),
          'val_global_score': 12.659180223941803,
          'val_loss': tensor(0.6464, device='cuda:0'),
          'val_precision': tensor(0.6949),
          'val_recall': tensor(0.6770)}
message: {'global_checkpoint': 1,
          'global_early_stopping': 0,
          'train_global_score': 9.212992658217743,
          'val_accuracy': tensor(0.6841),
          'val_demographic_parity_Marital': tensor(0.1074),
          'val_f1': tensor(0.6368),
          'val_global_score': 10.685622970263166,
          'val_loss': tensor(0.6218, device='cuda:0'),
          'val_precision': tensor(0.6957),
          'val_recall': tensor(0.6841)}
message: {'global_checkpoint': 1,
          'global_early_stopping': 0,
          'train_global_score': 6.575968603293103,
          'val_accuracy': tensor(0.6982),
          'val_demographic_parity_Marital': tensor(0.1566),
          'val_f1': tensor(0.6630),
          'val_global_score': 8.04143101970355,
          'val_loss': tensor(0.6105, device='cuda:0'),
          'val_precision': tensor(0.7072),
          'val_recall': tensor(0.6982)}
message: {'global_checkpoint': 0,
          'global_early_stopping': 1,
          'train_global_score': 10.720351745684937,
          'val_accuracy': tensor(0.6800),
          'val_demographic_parity_Marital': tensor(0.1048),
          'val_f1': tensor(0.6228),
          'val_global_score': 12.10116597016652,
          'val_loss': tensor(0.6605, device='cuda:0'),
          'val_precision': tensor(0.6987),
          'val_recall': tensor(0.6800)}
message: {'global_checkpoint': 1,
          'global_early_stopping': 0,
          'train_global_score': 5.530355840921401,
          'val_accuracy': tensor(0.6852),
          'val_demographic_parity_Marital': tensor(0.2133),
          'val_f1': tensor(0.6766),
          'val_global_score': 6.664242883523301,
          'val_loss': tensor(0.6395, device='cuda:0'),
          'val_precision': tensor(0.6771),
          'val_recall': tensor(0.6852)}
message: {'global_checkpoint': 0,
          'global_early_stopping': 1,
          'train_global_score': 12.955235183238983,
          'val_accuracy': tensor(0.6715),
          'val_demographic_parity_Marital': tensor(0.0800),
          'val_f1': tensor(0.5980),
          'val_global_score': 14.606348504622773,
          'val_loss': tensor(0.6291, device='cuda:0'),
          'val_precision': tensor(0.7020),
          'val_recall': tensor(0.6715)}
message: {'global_checkpoint': 0,
          'global_early_stopping': 2,
          'train_global_score': 8.911181509494781,
          'val_accuracy': tensor(0.6867),
          'val_demographic_parity_Marital': tensor(0.1225),
          'val_f1': tensor(0.6397),
          'val_global_score': 10.39226098855336,
          'val_loss': tensor(0.6496, device='cuda:0'),
          'val_precision': tensor(0.6966),
          'val_recall': tensor(0.6867)}
message: {'global_checkpoint': 0,
          'global_early_stopping': 3,
          'train_global_score': 10.807384888331098,
          'val_accuracy': tensor(0.6824),
          'val_demographic_parity_Marital': tensor(0.0975),
          'val_f1': tensor(0.6212),
          'val_global_score': 12.255365024010343,
          'val_loss': tensor(0.6069, device='cuda:0'),
          'val_precision': tensor(0.7094),
          'val_recall': tensor(0.6824)}
message: {'global_checkpoint': 0,
          'global_early_stopping': 4,
          'train_global_score': 8.137783229351044,
          'val_accuracy': tensor(0.6946),
          'val_demographic_parity_Marital': tensor(0.1287),
          'val_f1': tensor(0.6488),
          'val_global_score': 9.475629210472107,
          'val_loss': tensor(0.6322, device='cuda:0'),
          'val_precision': tensor(0.7102),
          'val_recall': tensor(0.6946)}
